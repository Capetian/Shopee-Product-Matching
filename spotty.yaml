# You must delete disks manually on GCP :\
# https://console.cloud.google.com/compute/disks?project=hear2021-evaluation

project:
  name: spotty-pytorch-env
  syncFilters:
    - exclude:
        - .idea/*
        - .git/*
        - '*/__pycache__/*'
        - _workdir/*
        - tasks/*
        - embeddings/*
        - .mypy_cache/*
        - lightning_logs/*
        - heareval.egg-info/*
        - pretrained/*
        - data/*
        - .ipynb_checkpoints/*
        - training_notebooks/models/*

containers:
  - projectDir: /workspace/project
    file: docker/Dockerfile.spotty
    ports:
      # TensorBoard
      - containerPort: 6006
        hostPort: 6006
      # Jupyter
      - containerPort: 8888
        hostPort: 8888
    volumeMounts:
      - name: workspace
        mountPath: /workspace
    runtimeParameters: [ '--gpus', 'all', '--ipc', 'host']
    # runtimeParameters: [ '--ipc', 'host']

instances:
  - name: spotty-pytorch-env-i1
    provider: gcp
    parameters:
      # https://cloud.google.com/compute/docs/gpus/gpu-regions-zones
      zone: us-central1-a
      # V100 
      machineType: n1-standard-4
      # One CPU seems to exhaust memory and crash
      #machineType: n1-standard-1
      ## A100. only west3 or maybe west4? :\
      #machineType: a2-highgpu-1g
      preemptibleInstance: True
      gpu:
        type: nvidia-tesla-v100
        #type: nvidia-tesla-a100
        count: 1
      # https://console.cloud.google.com/compute/images?project=hear2021-evaluation
      # https://github.com/spotty-cloud/spotty/issues/102
      #imageUri: projects/ml-images/global/images/c0-deeplearning-common-cu110-v20221107-debian-10
      #imageUri: projects/ml-images/global/images/c2-deeplearning-pytorch-1-12-cu113-v20221107-debian-10
      imageUri: projects/ml-images/global/images/c2-deeplearning-pytorch-1-11-cu113-v20220701-debian-10
      ports: [6006, 8888]
      dockerDataRoot: /docker
      volumes:
        - name: workspace
          parameters:
            size: 30
            mountDir: /workspace
        - name: docker
          parameters:
            size: 40
            mountDir: /docker

# Pick SR!
#   gsutil -m cp gs://hear2021/open-tasks/hear2021-task-*.tar . && for f in hear2021-task-*.tar; do tar xf "$f"; done
#   gsutil -m cp gs://hear2021/open-tasks/hear2021-task-*sr48000.tar . && for f in hear2021-task-*sr48000.tar; do tar xf "$f"; done
#   wget https://github.com/hearbenchmark/hear-baseline/raw/main/saved_models/naive_baseline.pt
#   python3 -m heareval.embeddings.runner hearbaseline --model naive_baseline.pt
#   python3 -m heareval.predictions.runner hearbaseline --model ./naive_baseline.pt
#   python3 -m heareval.evaluation.runner
#   
scripts:
  # get: |
  #   gsutil -m cp gs://hear2021/open-tasks/hear2021-task-*.tar . && for f in hear2021-task-*.tar; do tar xf "$f"; done
  # setup: |
  #   bash setup.sh
  # train: |
  #   bash train.sh
  tensorboard: |
    tensorboard --bind_all --port 6006 --logdir /workspace/project/logs
  jupyter: |
    jupyter lab --allow-root --ip 0.0.0.0 --notebook-dir=/workspace/project
