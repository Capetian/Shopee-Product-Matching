{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a5baf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T12:13:01.562243Z",
     "iopub.status.busy": "2022-11-23T12:13:01.561091Z",
     "iopub.status.idle": "2022-11-23T12:13:01.572884Z",
     "shell.execute_reply": "2022-11-23T12:13:01.572010Z"
    },
    "papermill": {
     "duration": 0.020637,
     "end_time": "2022-11-23T12:13:01.575343",
     "exception": false,
     "start_time": "2022-11-23T12:13:01.554706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('../tools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9c596a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T12:13:13.326706Z",
     "iopub.status.busy": "2022-11-23T12:13:13.326367Z",
     "iopub.status.idle": "2022-11-23T12:13:17.040920Z",
     "shell.execute_reply": "2022-11-23T12:13:17.039916Z"
    },
    "papermill": {
     "duration": 3.722111,
     "end_time": "2022-11-23T12:13:17.043506",
     "exception": false,
     "start_time": "2022-11-23T12:13:13.321395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tools.train_utils as utils\n",
    "# import train_utils as utils\n",
    "from transformers import AutoModel, BertTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5849fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data'\n",
    "# base_path = '../data'\n",
    "image_path = base_path + '/train_images/'\n",
    "saved_path = base_path + '/saved_models/text_model/'\n",
    "model_name = 'fine_tune_5epoch_bertindo15g-bs-64-mgrad-m06-08'\n",
    "model_file = saved_path + model_name +'.pth'\n",
    "BERT_PATH = base_path + '/bert-indo-15g'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c491ace0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T12:13:17.054556Z",
     "iopub.status.busy": "2022-11-23T12:13:17.052613Z",
     "iopub.status.idle": "2022-11-23T12:13:18.509111Z",
     "shell.execute_reply": "2022-11-23T12:13:18.507994Z"
    },
    "papermill": {
     "duration": 1.464386,
     "end_time": "2022-11-23T12:13:18.511879",
     "exception": false,
     "start_time": "2022-11-23T12:13:17.047493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = utils.no_split(pd.read_csv(base_path + '/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3997bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONF(utils.ConfigClass):\n",
    "    bs = 128\n",
    "    embedding_size = 768\n",
    "\n",
    "conf = CONF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b804db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T12:13:18.523129Z",
     "iopub.status.busy": "2022-11-23T12:13:18.522806Z",
     "iopub.status.idle": "2022-11-23T12:13:18.543989Z",
     "shell.execute_reply": "2022-11-23T12:13:18.543112Z"
    },
    "papermill": {
     "duration": 0.029189,
     "end_time": "2022-11-23T12:13:18.546135",
     "exception": false,
     "start_time": "2022-11-23T12:13:18.516946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertArcFace(nn.Module):\n",
    "    def __init__(self, bert_path):\n",
    "        super().__init__()\n",
    "        self.bert_model = AutoModel.from_pretrained(bert_path)\n",
    "    def forward(self, x):\n",
    "        output = self.bert_model(*x)\n",
    "        return output.last_hidden_state[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4baae171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert_model(fname, bert_path):\n",
    "    model = BertArcFace(bert_path=bert_path)\n",
    "    state = torch.load(fname)\n",
    "    model.load_state_dict(state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97559d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e88be95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at data/bert-indo-15g were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = load_bert_model(model_file, BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6422b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = utils.get_text_dls(train_df,tokenizer, conf.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5596cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6' class='' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.24% [6/268 00:07&lt;05:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/training_notebooks/make-embedding-text.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6c61756768696e675f766f6c68617264227d/workspace/training_notebooks/make-embedding-text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m embeddings \u001b[39m=\u001b[39m get_embeddings(model,dls,conf\u001b[39m.\u001b[39;49membedding_size)\u001b[39m.\u001b[39mcpu()\n",
      "\u001b[1;32m/workspace/training_notebooks/make-embedding-text.ipynb Cell 13\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(model, dls, embedding_size)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6c61756768696e675f766f6c68617264227d/workspace/training_notebooks/make-embedding-text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_embeddings\u001b[39m(model,dls, embedding_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6c61756768696e675f766f6c68617264227d/workspace/training_notebooks/make-embedding-text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     learn \u001b[39m=\u001b[39m Learner(dls\u001b[39m=\u001b[39m dls, model\u001b[39m=\u001b[39mModelGetEmbeddingWrapper(model, embedding_size\u001b[39m=\u001b[39membedding_size), loss_func\u001b[39m=\u001b[39mNoLoss(),cbs\u001b[39m=\u001b[39mGetEmbs())\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6c61756768696e675f766f6c68617264227d/workspace/training_notebooks/make-embedding-text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     learn\u001b[39m.\u001b[39;49mvalidate()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6c61756768696e675f766f6c68617264227d/workspace/training_notebooks/make-embedding-text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m learn\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcollected\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/learner.py:270\u001b[0m, in \u001b[0;36mLearner.validate\u001b[0;34m(self, ds_idx, dl, cbs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate\u001b[39m(\u001b[39mself\u001b[39m, ds_idx\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, dl\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cbs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m dl \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: dl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls[ds_idx]\n\u001b[0;32m--> 270\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_context(cbs\u001b[39m=\u001b[39mcbs): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch_validate(ds_idx, dl)\n\u001b[1;32m    271\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfinal_record\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/learner.py:236\u001b[0m, in \u001b[0;36mLearner._do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m dl \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: dl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls[ds_idx]\n\u001b[1;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl \u001b[39m=\u001b[39m dl\n\u001b[0;32m--> 236\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_batches, \u001b[39m'\u001b[39;49m\u001b[39mvalidate\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelValidException)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall_batches\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl): \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mone_batch(\u001b[39m*\u001b[39mo)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/data/load.py:130\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m _loaders[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfake_l\u001b[39m.\u001b[39mnum_workers\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m](\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfake_l):\n\u001b[1;32m    128\u001b[0m     \u001b[39m# pin_memory causes tuples to be converted to lists, so convert them back to tuples\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpin_memory \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(b) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m: b \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(b)\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: b \u001b[39m=\u001b[39m to_device(b, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    131\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter_batch(b)\n\u001b[1;32m    132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter_iter()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/torch_core.py:291\u001b[0m, in \u001b[0;36mto_device\u001b[0;34m(b, device, non_blocking)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39m#         if hasattr(o, \"to_device\"): return o.to_device(device)\u001b[39;00m\n\u001b[1;32m    290\u001b[0m         \u001b[39mreturn\u001b[39;00m o\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m apply(_inner, b)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/torch_core.py:222\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(func, x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mApply `func` recursively to `x`, passing on args\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mif\u001b[39;00m is_listy(x): \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(x)([apply(func, o, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m x])\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mdict\u001b[39m):  \u001b[39mreturn\u001b[39;00m {k: apply(func, v, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    224\u001b[0m     res \u001b[39m=\u001b[39m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/torch_core.py:222\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(func, x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mApply `func` recursively to `x`, passing on args\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mif\u001b[39;00m is_listy(x): \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(x)([apply(func, o, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m x])\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mdict\u001b[39m):  \u001b[39mreturn\u001b[39;00m {k: apply(func, v, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    224\u001b[0m     res \u001b[39m=\u001b[39m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/torch_core.py:222\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(func, x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mApply `func` recursively to `x`, passing on args\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mif\u001b[39;00m is_listy(x): \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(x)([apply(func, o, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m x])\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mdict\u001b[39m):  \u001b[39mreturn\u001b[39;00m {k: apply(func, v, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    224\u001b[0m     res \u001b[39m=\u001b[39m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/torch_core.py:222\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(func, x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mApply `func` recursively to `x`, passing on args\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mif\u001b[39;00m is_listy(x): \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(x)([apply(func, o, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m x])\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mdict\u001b[39m):  \u001b[39mreturn\u001b[39;00m {k: apply(func, v, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    224\u001b[0m     res \u001b[39m=\u001b[39m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/torch_core.py:224\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m is_listy(x): \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(x)([apply(func, o, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m x])\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mdict\u001b[39m):  \u001b[39mreturn\u001b[39;00m {k: apply(func, v, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m--> 224\u001b[0m res \u001b[39m=\u001b[39m func(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    225\u001b[0m \u001b[39mreturn\u001b[39;00m res \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/fastai/torch_core.py:288\u001b[0m, in \u001b[0;36mto_device.<locals>._inner\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m_inner\u001b[39m(o):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(o,Tensor): \u001b[39mreturn\u001b[39;00m o\u001b[39m.\u001b[39;49mto(device, non_blocking\u001b[39m=\u001b[39;49mnon_blocking)\n\u001b[1;32m    289\u001b[0m \u001b[39m#         if hasattr(o, \"to_device\"): return o.to_device(device)\u001b[39;00m\n\u001b[1;32m    290\u001b[0m         \u001b[39mreturn\u001b[39;00m o\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings = utils.get_embeddings(model,dls,conf.embedding_size).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183bf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_folder =  '../data/saved_embeddings/text_embeddings/'\n",
    "# save_name = model_name + '.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(embeddings, save_folder + save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528129c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1612.602306,
   "end_time": "2022-11-23T12:39:45.971645",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-23T12:12:53.369339",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
